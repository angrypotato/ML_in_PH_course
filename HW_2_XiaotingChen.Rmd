---
title: "HW 2"
author: "Xiaoting Chen"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warnings = FALSE, fig.align = 'center',  eval = TRUE)
```

We will be predicting whether the housing price is expensive or not using the `sahp` dataset in the **r02pro** package. 

You can run the following code to prepare the analysis.
```{r, message=F, warning=FALSE}
library(r02pro)     
library(tidyverse)  
library(MASS)
my_sahp <- sahp %>% 
  na.omit() %>%
  mutate(expensive = sale_price > median(sale_price)) %>%
  dplyr::select(gar_car, liv_area, oa_qual, expensive) 
my_sahp_train <- my_sahp[1:100, ]
my_sahp_test <- my_sahp[-(1:100), ]
```

Please answer the following questions.

1. a. Using the training data `my_sahp_train` to fit a logistic regression model of `expensive` on each variable (`gar_car`, `liv_area`, `oa_qual`) separately. For each logistic regression, compute the training and test error. Which variable leads to the smallest training error? Which variable leads to the smallest test error? 
 
b. Using the training data `my_sahp_train` to fit a logistic regression model of `expensive` on all three variables (`gar_car`, `liv_area`, `oa_qual`). Compute the training and test error. How do the result compare with part a.

```{r Q1}
lr <- function(iv, data = my_sahp_train) {
  formula <- paste0("expensive ~ ", iv)
  fit <- glm(formula, data = my_sahp_train, family='binomial')
  pred_train <- predict(fit, type = 'response')
  label_train <- ifelse(pred_train > 0.5, 'TRUE', 'FALSE')
  tr <- mean(label_train != my_sahp_train$expensive)
  pred_test <- predict(fit, newdata = my_sahp_test, type = 'response')
  label_test <- ifelse(pred_test > 0.5, 'TRUE', 'FALSE')
  te <- mean(label_test != my_sahp_test$expensive)
  output <- data.frame(IV = iv, train_error = tr, test_error = te)
  output
}
rbind(lr("gar_car"), lr("liv_area"), lr("oa_qual"))

# using all three variables as predictors
lr("gar_car + liv_area + oa_qual")
```
a. According to the results above, `oa_qual` leads to the smallest training error, and `gar_car` leads to the smallest test error.

b. The logistic regression model of `expensive` on all three variables performs better than any model using a single predictor in part a, with lower training and test errors.



2. Using the training data `my_sahp_train` to fit LDA and QDA models of `expensive` on all three variables (`gar_car`, `liv_area`, `oa_qual`). Compute the training and test error. How do the results compare with Q1? 

```{r Q2}
# LDA model
lda_fit <- lda(expensive ~ ., data = my_sahp_train)
lda_tr_pred <- predict(lda_fit, my_sahp_train)$class
lda_tr_error <- mean(lda_tr_pred != my_sahp_train$expensive)
lda_te_pred <- predict(lda_fit, my_sahp_test)$class
lda_te_error <- mean(lda_te_pred != my_sahp_test$expensive)

# QDA model
qda_fit <- qda(expensive ~ ., data = my_sahp_train)
qda_tr_pred <- predict(qda_fit, my_sahp_train)$class
qda_tr_error <- mean(qda_tr_pred != my_sahp_train$expensive)
qda_te_pred <- predict(qda_fit, my_sahp_test)$class
qda_te_error <- mean(qda_te_pred != my_sahp_test$expensive)

data.frame(model = c("LDA", "QDA"), 
           train_error = c(lda_tr_error, qda_tr_error),
           test_error = c(lda_te_error, qda_te_error))
```
The LDA and QDA models both have a lower training error and higher test error than the multiple logistic regression model in Q1.


3. Q3 in Chapter 4 of ISLRv2. 
![](q3.jpg)

4. Q6 in Chapter 4 of ISLRv2. 
![](q4.jpg)

```{r Q4}
# calculation
exp(-6 + 0.05 * 40 + 3.5)/(1 + exp(-6 + 0.05 * 40 + 3.5))
```

